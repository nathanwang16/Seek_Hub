# 系统需先安装 Tesseract 主程序 (Linux: sudo apt-get install tesseract-ocr)
# 并安装中文简体和英文语言包:
#   sudo apt-get install tesseract-ocr-chi-sim tesseract-ocr-eng

# Python 依赖
%pip install PyMuPDF pillow pytesseract ebooklib
# （若采用 Calibre / Pandoc 方案，再把它们装到系统即可）

import re
import os
import fitz  # PyMuPDF
import pytesseract
from PIL import Image
from tempfile import mkstemp
from pathlib import Path

# ----------  参数 ----------
TESSERACT_LANG = "eng+chi_sim"      # 同时识别英语+简体中文
OCR_DPI        = 600                # 渲染图片分辨率，数值越高 OCR 越准确
MAX_IMG_MB     = 20                 # 单张渲染图片大小上限 (MB) 防止内存炸

# ------------------------------------------------------------
#  OCR 辅助函数（PDF 分支独用）
# ------------------------------------------------------------
def _ocr_page(page) -> str:
    """渲染单页→Tesseract OCR，保留原有高清 & 限制大小逻辑"""
    zoom = OCR_DPI / 72
    mat  = fitz.Matrix(zoom, zoom)
    pix  = page.get_pixmap(matrix=mat)

    # 避免巨大图片
    img_mb = (pix.width * pix.height * 4) / (1024 * 1024)
    if img_mb > MAX_IMG_MB:
        scale = (MAX_IMG_MB * 1024 * 1024 / (pix.width * pix.height * 4)) ** 0.5
        mat   = fitz.Matrix(scale, scale)
        pix   = page.get_pixmap(matrix=mat)

    fd, tmp = mkstemp(suffix=".png")
    os.close(fd)
    pix.save(tmp)

    img  = Image.open(tmp)
    text = pytesseract.image_to_string(img, lang=TESSERACT_LANG)
    os.remove(tmp)
    return text


# ------------------------------------------------------------
#  统一入口：PDF / EPUB 自动识别 → TXT
# ------------------------------------------------------------
def convert_to_txt(file_path: str, txt_path: str | None = None) -> None:
    """
    PDF 或 EPUB → 纯文本 → postprocess → 保存为 .txt
    - 若 txt_path=None，则与原文件同名、改 .txt 后缀
    """
    file_path = Path(file_path)
    if txt_path is None:
        txt_path = file_path.with_suffix(".txt")
    else:
        txt_path = Path(txt_path)

    ext = file_path.suffix.lower()

    # =========== PDF ===========
    if ext == ".pdf":
        doc = fitz.open(file_path)
        out_lines = []

        for page_num, page in enumerate(doc, 1):
            text = page.get_text("text")
            if text.strip():
                out_lines.append(text)          # 文字层
            else:
                out_lines.append(_ocr_page(page))  # OCR 回退

            if page_num % 10 == 0:              # 保留原进度提示
                print(f"Processed page {page_num}/{len(doc)}")

        raw_text = "\n".join(out_lines)

    # =========== EPUB ==========
    elif ext == ".epub":
        import ebooklib
        from ebooklib import epub
        from bs4 import BeautifulSoup

        book   = epub.read_epub(file_path)
        chunks = []
        for item in book.get_items_of_type(ebooklib.ITEM_DOCUMENT):
            soup = BeautifulSoup(item.get_content(), "lxml")
            chunks.append(soup.get_text(separator="\n"))
        raw_text = "\n\n".join(chunks)

    else:
        raise ValueError("仅支持 .pdf 或 .epub 文件")

    # 统一清洗 & 保存
    #cleaned = postprocess(raw_text)
    #txt_path.write_text(cleaned, encoding="utf-8")
    #print(f"✓ Saved => {txt_path}")


# ------------------------------------------------------------
#  保留老接口：仍可直接调用 pdf_to_txt / epub_to_txt
# ------------------------------------------------------------
def pdf_to_txt(pdf_path: str, txt_path: str | None = None) -> None:
    """向后兼容：内部调用 convert_to_txt()"""
    convert_to_txt(pdf_path, txt_path)


def epub_to_txt(epub_path: str, txt_path: str | None = None) -> None:
    """向后兼容：内部调用 convert_to_txt()"""
    convert_to_txt(epub_path, txt_path)



# ----------  文本清洗 ----------


import re
from pathlib import Path
from collections import Counter

# 英/中文句末标点，用于判断是否应该合并下一行
_SENT_END = r"[.!?。！？]"

# 判定“高频页眉/页脚”用的阈值：出现次数 > 总行数 × THRESHOLD 即认为是噪声
_HEADER_THRESHOLD = 0.6


def postprocess(raw: str) -> str:
    """
    对 PDF/EPUB 提取出的原始文本进行清洗，返回 UTF-8 字符串。
    步骤：
    0) 换行/控制字符标准化
    1) 去页码 + 高频页眉页脚
    2) 合并断行，保留空行作段落分隔
    3) 修复跨行连字符 “hy-\nphen”
    4) 折叠多余空行
    5) 可选：标点半/全角转换、繁简体转换等
    """

    # ------------------------------------------------------------------ #
    # 0) 统一换行符 & 去除控制字符                                        #
    # ------------------------------------------------------------------ #
    txt = (
        raw.replace("\r\n", "\n")          # CRLF → LF
           .replace("\r", "\n")            # CR → LF
           .lstrip("\ufeff")               # 去 UTF-8 BOM
    )
    # 删除除 LF/TAB 外的其他 ASCII 控制字符
    txt = re.sub(r"[\x00-\x09\x0B-\x1F\x7F]", "", txt)

    lines = txt.split("\n")

    # ------------------------------------------------------------------ #
    # 1) 去孤立页码 & 高频页眉/页脚                                      #
    # ------------------------------------------------------------------ #
    pat_page = re.compile(r"^\s*(?:Page\s*)?\d{1,4}\s*(?:页|Page)?\s*$")
    trimmed = [ln.strip() for ln in lines if ln.strip()]
    # 统计出现频次，出现率超过阈值且长度 <80 的行视为模板化噪声
    common  = {ln for ln, c in Counter(trimmed).items()
                     if c > len(lines) * _HEADER_THRESHOLD and len(ln) < 80}

    def is_noise(line: str) -> bool:
        return pat_page.match(line) or line.strip() in common

    content_lines = [ln for ln in lines if not is_noise(ln)]

    # ------------------------------------------------------------------ #
    # 2) 合并断行：非句末行与下一行拼接                                  #
    # ------------------------------------------------------------------ #
    merged, buf = [], ""
    for ln in content_lines:
        if not ln.strip():           # 空行 → 段落边界
            if buf:
                merged.append(buf)
                buf = ""
            continue

        buf += ln.strip()            # 去两端空白再拼
        if re.search(_SENT_END + r"$", ln):  # 句末标点→刷新缓冲
            merged.append(buf)
            buf = ""
        else:
            buf += " "               # 行内继续，加空格

    if buf:
        merged.append(buf)

    # ------------------------------------------------------------------ #
    # 3) 修复 “hy-\nphen” 这类跨行连字符                                 #
    # ------------------------------------------------------------------ #
    text_block = "\n".join(merged)
    text_block = re.sub(r"-\s*\n([a-zA-Z])", r"\1", text_block)

    # ------------------------------------------------------------------ #
    # 4) 连续 ≥3 个换行压缩成 1 个空行                                   #
    # ------------------------------------------------------------------ #
    text_block = re.sub(r"\n{3,}", "\n\n", text_block)

    # ------------------------------------------------------------------ #
    # 5) 可选增强：如需可取消注释                                        #
    # ------------------------------------------------------------------ #
    # # a) 全角书名号《》 → 半角引号
    # text_block = text_block.replace("《", "\"").replace("》", "\"")
    #
    # # b) 繁体转简体
    # # from opencc import OpenCC
    # # text_block = OpenCC("t2s").convert(text_block)

    return text_block.strip()







#-----------------main--------------------------------------------#
#epub
#检查文件是否存在

from pathlib import Path
epub_to_txt("北京枪声 (Unknown) (Z-Library).epub", "北京枪声 (Unknown) (Z-Library).epub.txt")
txt_path = Path("北京枪声 (Unknown) (Z-Library).epub.txt")
print(txt_path.exists())          # True → 文件确实写好了
print(txt_path.stat().st_size)    # 文件大小（字节）
from IPython.display import FileLink
FileLink(txt_path)      # 点击输出的蓝色链接即可下载
