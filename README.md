# 以下是微调相关教程和资源：

DeepSeek 671B微调指南
https://company.hpc-ai.com/blog/shocking-release-deepseek-671b-fine-tuning-guide-revealed-unlock-the-upgraded-deepseek-suite-with-one-click-ai-players-ecstatic

SiliconFlow Platform
https://docs.siliconflow.cn/cn/userguide/introduction

【【DeepSeek+LoRA+FastAPI】开发人员如何微调大模型并暴露接口给后端调用】 
https://www.bilibili.com/video/BV1R6P7eVEtd/?share_source=copy_web&vd_source=1c639bb59610c225121de6410fe19657

Fine-Tuning AI Large Language Models (LLM) for Precise Corporate Translations: A BLEU Score Study
https://medium.com/@haberlah/fine-tuning-ai-large-language-models-llm-for-precise-corporate-translations-a-bleu-score-study-0fc3bf645a96

LLM长上下文的问题https://www.linsight.cn/c4da56c0.html
解决方案基本上1.微调使用长文本2.改变模型架构（稀疏注意力机制）


